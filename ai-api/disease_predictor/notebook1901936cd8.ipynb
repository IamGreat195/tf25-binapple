{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.status.busy": "2025-10-11T19:53:54.777594Z",
     "iopub.status.idle": "2025-10-11T19:53:54.777903Z",
     "shell.execute_reply": "2025-10-11T19:53:54.777761Z",
     "shell.execute_reply.started": "2025-10-11T19:53:54.777746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-11T19:53:54.778972Z",
     "iopub.status.idle": "2025-10-11T19:53:54.779297Z",
     "shell.execute_reply": "2025-10-11T19:53:54.779124Z",
     "shell.execute_reply.started": "2025-10-11T19:53:54.779111Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\preme\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/abdallahalidev/plantvillage-dataset?dataset_version_number=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.04G/2.04G [05:33<00:00, 6.57MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\preme\\.cache\\kagglehub\\datasets\\abdallahalidev\\plantvillage-dataset\\versions\\3\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"abdallahalidev/plantvillage-dataset\")\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T19:53:55.431054Z",
     "iopub.status.busy": "2025-10-11T19:53:55.430868Z",
     "iopub.status.idle": "2025-10-11T19:53:55.673845Z",
     "shell.execute_reply": "2025-10-11T19:53:55.673186Z",
     "shell.execute_reply.started": "2025-10-11T19:53:55.431039Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/input/plantvillage-dataset\n",
    "\n",
    "!ls \"/kaggle/input/plantvillage-dataset/plantvillage dataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T19:53:55.675514Z",
     "iopub.status.busy": "2025-10-11T19:53:55.675317Z",
     "iopub.status.idle": "2025-10-11T19:53:55.691712Z",
     "shell.execute_reply": "2025-10-11T19:53:55.690995Z",
     "shell.execute_reply.started": "2025-10-11T19:53:55.675478Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset from: /kaggle/input/plantvillage-dataset/plantvillage dataset\\color\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/kaggle/input/plantvillage-dataset/plantvillage dataset\\\\color'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUsing dataset from:\u001b[39m\u001b[33m\"\u001b[39m, color_path)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Check what classes you have\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m classes = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolor_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mClasses found:\u001b[39m\u001b[33m\"\u001b[39m, classes[:\u001b[32m10\u001b[39m])  \u001b[38;5;66;03m# just show first 10\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: '/kaggle/input/plantvillage-dataset/plantvillage dataset\\\\color'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# This is where your dataset is\n",
    "dataset_path = \"/kaggle/input/plantvillage-dataset/plantvillage dataset\"\n",
    "\n",
    "# Go specifically to the color images\n",
    "color_path = os.path.join(dataset_path, \"color\")\n",
    "print(\"Using dataset from:\", color_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T19:53:55.692579Z",
     "iopub.status.busy": "2025-10-11T19:53:55.692380Z",
     "iopub.status.idle": "2025-10-11T19:53:55.696509Z",
     "shell.execute_reply": "2025-10-11T19:53:55.696012Z",
     "shell.execute_reply.started": "2025-10-11T19:53:55.692564Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('binary_dataset/Healthy', exist_ok=True)\n",
    "os.makedirs('binary_dataset/Not_Healthy', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T19:53:58.780969Z",
     "iopub.status.busy": "2025-10-11T19:53:58.780710Z",
     "iopub.status.idle": "2025-10-11T19:53:58.786090Z",
     "shell.execute_reply": "2025-10-11T19:53:58.785349Z",
     "shell.execute_reply.started": "2025-10-11T19:53:58.780950Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset from: /kaggle/input/plantvillage-dataset/plantvillage dataset\\color\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/kaggle/input/plantvillage-dataset/plantvillage dataset\"\n",
    "# Go specifically to the color images\n",
    "color_path = os.path.join(dataset_path, \"color\")\n",
    "print(\"Using dataset from:\", color_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T19:53:58.787578Z",
     "iopub.status.busy": "2025-10-11T19:53:58.787174Z",
     "iopub.status.idle": "2025-10-11T20:02:17.594871Z",
     "shell.execute_reply": "2025-10-11T20:02:17.594025Z",
     "shell.execute_reply.started": "2025-10-11T19:53:58.787559Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/kaggle/input/plantvillage-dataset/color'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m source_dir = \u001b[33m'\u001b[39m\u001b[33m/kaggle/input/plantvillage-dataset/color\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m dest_dir = \u001b[33m'\u001b[39m\u001b[33mbinary_dataset\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m      7\u001b[39m     folder_path = os.path.join(source_dir, folder)\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.isdir(folder_path):\n\u001b[32m      9\u001b[39m         \u001b[38;5;66;03m# Determine destination\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: '/kaggle/input/plantvillage-dataset/color'"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "source_dir = '/kaggle/input/plantvillage-dataset/color'\n",
    "dest_dir = 'binary_dataset'\n",
    "\n",
    "for folder in os.listdir(source_dir):\n",
    "    folder_path = os.path.join(source_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Determine destination\n",
    "        if 'healthy' in folder.lower():\n",
    "            target_folder = os.path.join(dest_dir, 'Healthy')\n",
    "        else:\n",
    "            target_folder = os.path.join(dest_dir, 'Not_Healthy')\n",
    "        \n",
    "        # Copy all images\n",
    "        for img_file in os.listdir(folder_path):\n",
    "            src_img = os.path.join(folder_path, img_file)\n",
    "            dst_img = os.path.join(target_folder, img_file)\n",
    "            shutil.copy(src_img, dst_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T20:06:27.002352Z",
     "iopub.status.busy": "2025-10-11T20:06:27.001771Z",
     "iopub.status.idle": "2025-10-11T20:06:27.263661Z",
     "shell.execute_reply": "2025-10-11T20:06:27.263043Z",
     "shell.execute_reply.started": "2025-10-11T20:06:27.002329Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Found no valid file for the classes Healthy, Not_Healthy. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Image transforms (resize + normalization)\u001b[39;00m\n\u001b[32m      8\u001b[39m transform = transforms.Compose([\n\u001b[32m      9\u001b[39m     transforms.Resize((\u001b[32m224\u001b[39m,\u001b[32m224\u001b[39m)),\n\u001b[32m     10\u001b[39m     transforms.ToTensor(),\n\u001b[32m     11\u001b[39m     transforms.Normalize([\u001b[32m0.485\u001b[39m,\u001b[32m0.456\u001b[39m,\u001b[32m0.406\u001b[39m], [\u001b[32m0.229\u001b[39m,\u001b[32m0.224\u001b[39m,\u001b[32m0.225\u001b[39m])  \u001b[38;5;66;03m# ImageNet stats\u001b[39;00m\n\u001b[32m     12\u001b[39m ])\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m train_dataset = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m val_dataset = datasets.ImageFolder(os.path.join(data_dir), transform=transform)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Split train/val manually (80/20)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\preme\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:328\u001b[39m, in \u001b[36mImageFolder.__init__\u001b[39m\u001b[34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    320\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    321\u001b[39m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m   (...)\u001b[39m\u001b[32m    326\u001b[39m     allow_empty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    327\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28mself\u001b[39m.imgs = \u001b[38;5;28mself\u001b[39m.samples\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\preme\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:150\u001b[39m, in \u001b[36mDatasetFolder.__init__\u001b[39m\u001b[34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(root, transform=transform, target_transform=target_transform)\n\u001b[32m    149\u001b[39m classes, class_to_idx = \u001b[38;5;28mself\u001b[39m.find_classes(\u001b[38;5;28mself\u001b[39m.root)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m samples = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;28mself\u001b[39m.loader = loader\n\u001b[32m    159\u001b[39m \u001b[38;5;28mself\u001b[39m.extensions = extensions\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\preme\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:203\u001b[39m, in \u001b[36mDatasetFolder.make_dataset\u001b[39m\u001b[34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m class_to_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    199\u001b[39m     \u001b[38;5;66;03m# prevent potential bug since make_dataset() would use the class_to_idx logic of the\u001b[39;00m\n\u001b[32m    200\u001b[39m     \u001b[38;5;66;03m# find_classes() function, instead of using that of the find_classes() method, which\u001b[39;00m\n\u001b[32m    201\u001b[39m     \u001b[38;5;66;03m# is potentially overridden and thus could have a different logic.\u001b[39;00m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe class_to_idx parameter cannot be None.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_to_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_empty\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\preme\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:104\u001b[39m, in \u001b[36mmake_dataset\u001b[39m\u001b[34m(directory, class_to_idx, extensions, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    103\u001b[39m         msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSupported extensions are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextensions\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28misinstance\u001b[39m(extensions,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(extensions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(msg)\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m instances\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Found no valid file for the classes Healthy, Not_Healthy. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_dir = 'binary_dataset'\n",
    "\n",
    "# Image transforms (resize + normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])  # ImageNet stats\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_dir), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(data_dir), transform=transform)\n",
    "\n",
    "# Split train/val manually (80/20)\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "total_len = len(train_dataset)\n",
    "train_len = int(0.8 * total_len)\n",
    "val_len = total_len - train_len\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_len, val_len])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T20:06:50.117318Z",
     "iopub.status.busy": "2025-10-11T20:06:50.117060Z",
     "iopub.status.idle": "2025-10-11T20:06:50.853853Z",
     "shell.execute_reply": "2025-10-11T20:06:50.853298Z",
     "shell.execute_reply.started": "2025-10-11T20:06:50.117299Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to C:\\Users\\preme/.cache\\torch\\hub\\checkpoints\\efficientnet_b0_rwightman-7f5810bc.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20.5M/20.5M [00:02<00:00, 9.88MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load pretrained EfficientNetB0\n",
    "model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "# Replace classifier for binary output\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)  # 1 output\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T20:06:54.882394Z",
     "iopub.status.busy": "2025-10-11T20:06:54.882125Z",
     "iopub.status.idle": "2025-10-11T20:34:51.275784Z",
     "shell.execute_reply": "2025-10-11T20:34:51.274944Z",
     "shell.execute_reply.started": "2025-10-11T20:06:54.882374Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m correct = \u001b[32m0\u001b[39m\n\u001b[32m     10\u001b[39m total = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mtrain_loader\u001b[49m):\n\u001b[32m     13\u001b[39m     images, labels = images.to(device), labels.float().unsqueeze(\u001b[32m1\u001b[39m).to(device)  \u001b[38;5;66;03m# BCE expects float\u001b[39;00m\n\u001b[32m     14\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[31mNameError\u001b[39m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()  # combines sigmoid + BCE\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 5  # increase later\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images, labels = images.to(device), labels.float().unsqueeze(1).to(device)  # BCE expects float\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "    val_acc = val_correct / val_total\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T20:47:26.027876Z",
     "iopub.status.busy": "2025-10-11T20:47:26.027271Z",
     "iopub.status.idle": "2025-10-11T20:47:26.057246Z",
     "shell.execute_reply": "2025-10-11T20:47:26.056535Z",
     "shell.execute_reply.started": "2025-10-11T20:47:26.027854Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Not Healthy\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "img_path = 'image.png'\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "img = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(img)\n",
    "    pred = torch.sigmoid(output) > 0.5\n",
    "    print(\"Prediction:\", \"Not Healthy\" if pred.item() else \"Healthy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T20:45:52.003177Z",
     "iopub.status.busy": "2025-10-11T20:45:52.002583Z",
     "iopub.status.idle": "2025-10-11T20:45:52.067280Z",
     "shell.execute_reply": "2025-10-11T20:45:52.066711Z",
     "shell.execute_reply.started": "2025-10-11T20:45:52.003154Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved to 'model_weights.pth'\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')\n",
    "print(\"Model weights saved to 'model_weights.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded!\n"
     ]
    }
   ],
   "source": [
    "model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('model_weights.pth', map_location=device))\n",
    "model.eval()  # Set to evaluation mode\n",
    "print(\"Model weights loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 277323,
     "sourceId": 658267,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
