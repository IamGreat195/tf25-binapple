{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpERLMQqHwHL",
        "outputId": "1fde9e05-8488-4b7c-ee9d-e7c8a49bba34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: segmentation-models-pytorch in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.5.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from segmentation-models-pytorch) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from segmentation-models-pytorch) (1.26.4)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from segmentation-models-pytorch) (11.2.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from segmentation-models-pytorch) (0.5.3)\n",
            "Requirement already satisfied: timm>=0.9 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from segmentation-models-pytorch) (1.0.20)\n",
            "Requirement already satisfied: torch>=1.8 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from segmentation-models-pytorch) (2.7.1+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from segmentation-models-pytorch) (0.22.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from segmentation-models-pytorch) (4.67.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\preme\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.14.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8->segmentation-models-pytorch) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8->segmentation-models-pytorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8->segmentation-models-pytorch) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\preme\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.42.1->segmentation-models-pytorch) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.6.15)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: albumentations==0.4.6 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.4.6)\n",
            "Requirement already satisfied: numpy>=1.11.1 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from albumentations==0.4.6) (1.26.4)\n",
            "Requirement already satisfied: scipy in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from albumentations==0.4.6) (1.13.1)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from albumentations==0.4.6) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from albumentations==0.4.6) (6.0.2)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from albumentations==0.4.6) (4.12.0.88)\n",
            "Requirement already satisfied: six in c:\\users\\preme\\appdata\\roaming\\python\\python311\\site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.17.0)\n",
            "Requirement already satisfied: Pillow in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (11.2.1)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.10.3)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.25.2)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (4.12.0.88)\n",
            "Requirement already satisfied: imageio in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.37.0)\n",
            "Requirement already satisfied: Shapely in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.1.1)\n",
            "Collecting numpy>=1.11.1 (from albumentations==0.4.6)\n",
            "  Using cached numpy-2.2.6-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (3.5)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2025.10.4)\n",
            "Requirement already satisfied: packaging>=21 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\preme\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\preme\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.9.0.post0)\n",
            "Using cached numpy-2.2.6-cp311-cp311-win_amd64.whl (12.9 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "Successfully installed numpy-2.2.6\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'c:\\Users\\preme\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\n",
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install segmentation-models-pytorch\n",
        "%pip install albumentations==0.4.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy<2.0\n",
            "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.6\n",
            "    Uninstalling numpy-2.2.6:\n",
            "      Successfully uninstalled numpy-2.2.6\n",
            "Successfully installed numpy-1.26.4\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The script f2py.exe is installed in 'c:\\Users\\preme\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "\n",
            "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install \"numpy<2.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "66IUD5fXnyrT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import segmentation_models_pytorch as smp\n",
        "from sklearn.model_selection import train_test_split\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "7JQVShGUpypD"
      },
      "outputs": [],
      "source": [
        "class cropDataset(Dataset):\n",
        "  def __init__(self, img_dir, mask_dir, files_list, transform=None):\n",
        "    self.img_dir = Path(img_dir)\n",
        "    self.mask_dir = Path(mask_dir)\n",
        "    self.files = files_list\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.files)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      name = self.files[idx]\n",
        "      img_path = os.path.join(self.img_dir, name)\n",
        "      mask_path = os.path.join(self.mask_dir, name)\n",
        "\n",
        "      img = cv2.imread(img_path)\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "      mask = (mask > 0).astype(np.float32)\n",
        "\n",
        "      if self.transform:\n",
        "          augmented = self.transform(image=img, mask=mask)\n",
        "          img = augmented['image']     # already Tensor [3, H, W]\n",
        "          mask = augmented['mask']     # already Tensor [H, W]\n",
        "          mask = mask.unsqueeze(0)     # make it [1, H, W]\n",
        "\n",
        "      else:\n",
        "          img = torch.from_numpy(img.transpose(2, 0, 1)).float()\n",
        "          mask = torch.from_numpy(mask).unsqueeze(0).float()\n",
        "\n",
        "      return img, mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "p4gbDPGpK5Iz"
      },
      "outputs": [],
      "source": [
        "def get_files_with_masks(images_dir, masks_dir):\n",
        "  images = set([f for f in os.listdir(images_dir) if f.endswith('.png')])\n",
        "  masks = set([f for f in os.listdir(masks_dir) if f.endswith('.png')])\n",
        "  return sorted(list(images & masks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "6iNgqIZuLz9N"
      },
      "outputs": [],
      "source": [
        "def compute_iou(pred, target, num_classes):\n",
        "  ious = []\n",
        "  for cls in range(num_classes):\n",
        "    pred_inds = pred == cls # boolean mask which is same shape as image for the predicted mask\n",
        "    target_inds = target == cls\n",
        "    intersection = (pred_inds & target_inds).sum() # .sum counts how many are true at the same place\n",
        "    union = (pred_inds | target_inds).sum()\n",
        "\n",
        "    if union == 0:\n",
        "      iou = float('nan')\n",
        "    else:\n",
        "      iou = intersection/union # percentage overlap\n",
        "\n",
        "    ious.append(iou)\n",
        "    valid_ious = [x for x in ious if str(x) != 'nan']\n",
        "    if len(valid_ious) == 0:\n",
        "      miou = 0.0\n",
        "    else:\n",
        "      miou = np.mean(valid_ious)\n",
        "\n",
        "    return miou, ious"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "g-Dmsb9MUKK1"
      },
      "outputs": [],
      "source": [
        "def visualize(img_tensor, mask_gt, mask_pred, out_path, class_colors=None):\n",
        "    # Convert image tensor to numpy\n",
        "    if isinstance(img_tensor, torch.Tensor):  # if its a tensor\n",
        "        img = img_tensor.detach().cpu().permute(1, 2, 0).numpy()\n",
        "    else:\n",
        "        img = img_tensor\n",
        "\n",
        "    # Normalize & convert to uint8\n",
        "    img = np.clip(img, 0, 1)\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "\n",
        "    # Convert masks to numpy\n",
        "    if isinstance(mask_gt, torch.Tensor):\n",
        "        mask_gt = mask_gt.detach().cpu().numpy()\n",
        "    if isinstance(mask_pred, torch.Tensor):\n",
        "        mask_pred = mask_pred.detach().cpu().numpy()\n",
        "\n",
        "    # Fix mask shapes\n",
        "    mask_gt = np.squeeze(mask_gt)\n",
        "    mask_pred = np.squeeze(mask_pred)\n",
        "\n",
        "    # Threshold for binary mask\n",
        "    mask_pred = (mask_pred > 0.5).astype(np.uint8)\n",
        "    mask_gt = mask_gt.astype(np.uint8)\n",
        "\n",
        "    # Prepare overlay\n",
        "    overlay = img.copy()\n",
        "\n",
        "    # Define colors (binary)\n",
        "    if class_colors is None:\n",
        "        class_colors = {\n",
        "            0: (0, 0, 0),      # background - black\n",
        "            1: (0, 255, 0),    # weeds - green\n",
        "        }\n",
        "\n",
        "    # Overlay prediction\n",
        "    for cls, color in class_colors.items():\n",
        "        mask = (mask_pred == cls)\n",
        "\n",
        "        # Make sure mask is 2D and boolean\n",
        "        mask = np.squeeze(mask).astype(bool)\n",
        "\n",
        "        if mask.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        # Blend with transparency\n",
        "        overlay[mask] = (overlay[mask] * 0.5 + np.array(color) * 0.5).astype(np.uint8)\n",
        "\n",
        "    # Plot and save\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    axs[0].imshow(img)\n",
        "    axs[0].set_title(\"Image\")\n",
        "    axs[0].axis(\"off\")\n",
        "\n",
        "    axs[1].imshow(mask_gt, cmap=\"gray\")\n",
        "    axs[1].set_title(\"Ground Truth\")\n",
        "    axs[1].axis(\"off\")\n",
        "\n",
        "    axs[2].imshow(overlay)\n",
        "    axs[2].set_title(\"Prediction Overlay\")\n",
        "    axs[2].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path)\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_pos_weight(loader):\n",
        "    total_pos, total_neg = 0, 0\n",
        "    for _, masks in loader:\n",
        "        total_pos += masks.sum().item()\n",
        "        total_neg += (1 - masks).sum().item()\n",
        "    pos_weight = total_neg / (total_pos + 1e-6)\n",
        "    print(f\"Dynamic pos_weight = {pos_weight:.2f}\")\n",
        "    return torch.tensor([pos_weight])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "gkvbR5mAde5H"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, optimizer, loss_fn, device, scaler=None):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for imgs, masks in tqdm(loader, desc='Train', leave=False):\n",
        "        imgs = imgs.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
        "            preds = model(imgs)\n",
        "            loss = loss_fn(preds, masks)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "\n",
        "    return running_loss / len(loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_with_class_iou(model, loader, loss_fn, device, num_classes, save_preds_dir=None, sample_limit=5):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "\n",
        "    # Accumulators for \"global\" IoU across the whole dataset\n",
        "    # intersection[c] = total pixels where (pred==c and gt==c)\n",
        "    # union[c]        = total pixels where (pred==c or  gt==c)\n",
        "    intersection = np.zeros(num_classes, dtype=np.int64)\n",
        "    union        = np.zeros(num_classes, dtype=np.int64)\n",
        "    support      = np.zeros(num_classes, dtype=np.int64)  # GT pixel count per class (optional but useful)\n",
        "\n",
        "    saved = 0\n",
        "\n",
        "    for imgs, masks in tqdm(loader, desc='Eval', leave=False):\n",
        "        imgs  = imgs.to(device)\n",
        "        masks = masks.to(device)  # [B, H, W] (Long)\n",
        "\n",
        "        preds = model(imgs)       # [B, C, H, W] (logits)\n",
        "        loss  = loss_fn(preds, masks)\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        probs = torch.sigmoid(preds)\n",
        "        pred_cls = (probs > 0.5).long()\n",
        "\n",
        "        # Move to numpy\n",
        "        p = pred_cls.cpu().numpy()\n",
        "        g = masks.cpu().numpy()\n",
        "\n",
        "        # Aggregate intersections/unions **per class** over the batch\n",
        "        # This computes \"global IoU\" (more stable than averaging per-image IoUs)\n",
        "        for c in range(num_classes):\n",
        "            pc = (p == c)\n",
        "            gc = (g == c)\n",
        "            inter = np.logical_and(pc, gc).sum()\n",
        "            uni   = np.logical_or(pc, gc).sum()\n",
        "\n",
        "            intersection[c] += inter\n",
        "            union[c]        += uni\n",
        "            support[c]      += gc.sum()\n",
        "\n",
        "        # (Optional) save a few visualizations\n",
        "        if save_preds_dir is not None and saved < sample_limit:\n",
        "            for i in range(min(p.shape[0], sample_limit - saved)):\n",
        "                img_np = imgs[i].cpu().permute(1, 2, 0).numpy()\n",
        "                img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min() + 1e-9)\n",
        "                out_path = os.path.join(str(save_preds_dir), f'eval_{saved}.png')\n",
        "                visualize(img_np, g[i], p[i], out_path)  # your visualize() handles numpy inputs\n",
        "                saved += 1\n",
        "                if saved >= sample_limit:\n",
        "                    break\n",
        "\n",
        "    # Compute mean loss\n",
        "    avg_loss = val_loss / max(1, len(loader))\n",
        "\n",
        "    # Per-class IoU (ignore classes with union == 0)\n",
        "    per_class_iou = []\n",
        "    for c in range(num_classes):\n",
        "        if union[c] == 0:\n",
        "            per_class_iou.append(float('nan'))\n",
        "        else:\n",
        "            per_class_iou.append(float(intersection[c]) / float(union[c]))\n",
        "\n",
        "    # mIoU over classes that actually appear\n",
        "    valid = [x for x in per_class_iou if not np.isnan(x)]\n",
        "    avg_miou = float(np.mean(valid)) if len(valid) else 0.0\n",
        "\n",
        "    return avg_loss, avg_miou, per_class_iou, support\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "8fIygFvj_pzA"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    img_size = 512\n",
        "    batch_size = 2\n",
        "    num_classes = 2\n",
        "    epochs = 60\n",
        "    lr = 1e-4\n",
        "    num_workers = 0\n",
        "    use_amp = True\n",
        "\n",
        "    images_dir = 'CoFly-WeedDB/CoFly-WeedDB/images'\n",
        "    masks_dir = 'CoFly-WeedDB/CoFly-WeedDB/labels'\n",
        "    os.makedirs('output', exist_ok=True)\n",
        "    preds_dir = Path('output') / 'preds'\n",
        "    preds_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    files = get_files_with_masks(images_dir, masks_dir)\n",
        "    print(\"Files found:\", files)\n",
        "    train_files, val_files = train_test_split(files, test_size=0.2, random_state=42)\n",
        "    print(f\"Found {len(files)} labeled images. Train: {len(train_files)}, Val: {len(val_files)}\")\n",
        "\n",
        "    train_transform = A.Compose([\n",
        "        A.Resize(img_size, img_size),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.RandomRotate90(p=0.5),\n",
        "        A.RandomBrightnessContrast(p=0.4),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "    val_transform = A.Compose([\n",
        "        A.Resize(img_size, img_size),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "    \n",
        "\n",
        "    # Datasets\n",
        "    train_ds = cropDataset(images_dir, masks_dir, train_files, train_transform)\n",
        "    val_ds = cropDataset(images_dir, masks_dir, val_files, val_transform)\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    model = smp.Unet(\n",
        "        encoder_name='resnet34',\n",
        "        encoder_weights='imagenet',\n",
        "        in_channels=3,\n",
        "        classes=1\n",
        "    )\n",
        "\n",
        "    dice = smp.losses.DiceLoss(mode='binary')\n",
        "    focal = smp.losses.FocalLoss(mode='binary')\n",
        "\n",
        "    def loss_fn(preds, targets):\n",
        "        bce = F.binary_cross_entropy_with_logits(preds, targets, pos_weight=pos_weight)\n",
        "        \n",
        "        # Dice loss (foreground overlap)\n",
        "        probs = torch.sigmoid(preds)\n",
        "        smooth = 1e-6\n",
        "        intersection = (probs * targets).sum()\n",
        "        dice = 1 - (2. * intersection + smooth) / (probs.sum() + targets.sum() + smooth)\n",
        "        \n",
        "        return 0.5 * bce + 0.5 * dice\n",
        "\n",
        "\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='max', factor=0.5, patience=3\n",
        "    )\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp and torch.cuda.is_available())\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    pos_weight = get_pos_weight(train_loader).to(device)\n",
        "\n",
        "    best_miou = -1.0\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
        "        train_loss = train(model, train_loader, optimizer, loss_fn, device,\n",
        "                           scaler=scaler if use_amp else None)\n",
        "        val_loss, val_miou, per_cls_iou, support = eval_with_class_iou(\n",
        "        model, val_loader, loss_fn, device, num_classes,\n",
        "        save_preds_dir=preds_dir, sample_limit=5\n",
        "    )\n",
        "\n",
        "        print(f\"Train loss: {train_loss:.4f} | Val loss: {val_loss:.4f} | Val mIoU: {val_miou:.4f}\")\n",
        "        print(\"Per-class IoU:\")\n",
        "        for c, (iou, sup) in enumerate(zip(per_cls_iou, support)):\n",
        "            sup_pct = 100.0 * sup / max(1, support.sum())\n",
        "            \n",
        "            print(f\"  Class {c}: IoU={0.0 if np.isnan(iou) else iou:.4f}  (support={sup} px, {sup_pct:.2f}% of GT)\")\n",
        "\n",
        "        scheduler.step(val_miou)\n",
        "\n",
        "        if val_miou > best_miou:\n",
        "            best_miou = val_miou\n",
        "            ckpt_path = os.path.join('output', 'best_model.pth')\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state': model.state_dict(),\n",
        "                'optimizer_state': optimizer.state_dict(),\n",
        "                'miou': best_miou\n",
        "            }, ckpt_path)\n",
        "            print(f\"Saved best model (mIoU={best_miou:.4f}) to {ckpt_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwlyoQ_OEt1y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files found: ['ID_00048_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54212427861807,Lon=22.64442951302024,Alt=4.900000095367432]_DATE_03_07_2019_14_38_56.png', 'ID_00049_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54212238368247,Lon=22.644427100249906,Alt=4.900000095367432]_DATE_03_07_2019_14_38_57.png', 'ID_00050_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54212050531792,Lon=22.644424707209755,Alt=4.900000095367432]_DATE_03_07_2019_14_38_58.png', 'ID_00051_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54211671867755,Lon=22.64441993246098,Alt=4.900000095367432]_DATE_03_07_2019_14_38_59.png', 'ID_00052_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54211477371615,Lon=22.644417506003943,Alt=4.900000095367432]_DATE_03_07_2019_14_38_59.png', 'ID_00053_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542112844908914,Lon=22.64441509154499,Alt=4.900000095367432]_DATE_03_07_2019_14_39_00.png', 'ID_00054_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54211093392337,Lon=22.644412730677484,Alt=4.900000095367432]_DATE_03_07_2019_14_39_00.png', 'ID_00055_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542083972622905,Lon=22.64437887492733,Alt=5.0]_DATE_03_07_2019_14_39_01.png', 'ID_00056_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54203384270712,Lon=22.6443173135562,Alt=4.900000095367432]_DATE_03_07_2019_14_39_01.png', 'ID_00057_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542029925582796,Lon=22.644312197750764,Alt=4.900000095367432]_DATE_03_07_2019_14_39_02.png', 'ID_00058_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54202799708822,Lon=22.644309643225288,Alt=4.900000095367432]_DATE_03_07_2019_14_39_04.png', 'ID_00061_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54190261857315,Lon=22.64415333458149,Alt=5.0]_DATE_03_07_2019_14_39_11.png', 'ID_00062_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54187150857059,Lon=22.64411475665194,Alt=5.0]_DATE_03_07_2019_14_39_13.png', 'ID_00063_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54186771494745,Lon=22.644109885874055,Alt=5.0]_DATE_03_07_2019_14_39_17.png', 'ID_00065_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541776905406316,Lon=22.643994037614803,Alt=4.900000095367432]_DATE_03_07_2019_14_39_22.png', 'ID_00068_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541760147284556,Lon=22.643725690503484,Alt=4.900000095367432]_DATE_03_07_2019_14_39_28.png', 'ID_00070_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.5417989584463,Lon=22.643530583432007,Alt=5.0]_DATE_03_07_2019_14_39_29.png', 'ID_00073_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193633033416,Lon=22.643550942314846,Alt=4.900000095367432]_DATE_03_07_2019_14_39_30.png', 'ID_00074_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193593867384,Lon=22.643553973830834,Alt=4.900000095367432]_DATE_03_07_2019_14_39_31.png', 'ID_00079_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.5419326810563,Lon=22.643614647699216,Alt=5.0]_DATE_03_07_2019_14_39_44.png', 'ID_00080_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193232587313,Lon=22.643662531609635,Alt=4.900000095367432]_DATE_03_07_2019_14_39_47.png', 'ID_00081_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193066147309,Lon=22.64400406907985,Alt=4.900000095367432]_DATE_03_07_2019_14_39_49.png', 'ID_00082_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541931324836035,Lon=22.644130139884748,Alt=4.900000095367432]_DATE_03_07_2019_14_39_50.png', 'ID_00083_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541931332861004,Lon=22.644133585734583,Alt=4.900000095367432]_DATE_03_07_2019_14_39_52.png', 'ID_00084_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541931345784334,Lon=22.644137027318433,Alt=4.900000095367432]_DATE_03_07_2019_14_39_55.png', 'ID_00085_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193136371025,Lon=22.64414047539014,Alt=4.900000095367432]_DATE_03_07_2019_14_39_57.png', 'ID_00086_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541931373298524,Lon=22.644143932704814,Alt=4.900000095367432]_DATE_03_07_2019_14_39_58.png', 'ID_00087_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193311304993,Lon=22.644217169634043,Alt=4.800000190734863]_DATE_03_07_2019_14_39_58.png', 'ID_00088_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193316161664,Lon=22.644220651922506,Alt=4.800000190734863]_DATE_03_07_2019_14_39_59.png', 'ID_00091_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193035860856,Lon=22.644614169849085,Alt=4.900000095367432]_DATE_03_07_2019_14_40_00.png', 'ID_00092_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193024896868,Lon=22.644621219879035,Alt=4.900000095367432]_DATE_03_07_2019_14_40_01.png', 'ID_00093_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193021155355,Lon=22.644624796730177,Alt=4.900000095367432]_DATE_03_07_2019_14_40_02.png', 'ID_00094_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541929993003336,Lon=22.64465317939861,Alt=5.0]_DATE_03_07_2019_14_40_04.png', 'ID_00096_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193248783165,Lon=22.644830630289068,Alt=4.900000095367432]_DATE_03_07_2019_14_40_10.png', 'ID_00097_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193245666975,Lon=22.644834155659538,Alt=5.0]_DATE_03_07_2019_14_40_11.png', 'ID_00098_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193299434287,Lon=22.645030887549375,Alt=4.900000095367432]_DATE_03_07_2019_14_40_13.png', 'ID_00099_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.5419328658391,Lon=22.645034397055714,Alt=4.900000095367432]_DATE_03_07_2019_14_40_15.png', 'ID_00100_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541930220203845,Lon=22.645153785110914,Alt=4.900000095367432]_DATE_03_07_2019_14_40_17.png', 'ID_00102_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193230982318,Lon=22.64534371619212,Alt=4.900000095367432]_DATE_03_07_2019_14_40_24.png', 'ID_00103_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193219153301,Lon=22.64534728082299,Alt=4.900000095367432]_DATE_03_07_2019_14_40_25.png', 'ID_00106_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541931716392135,Lon=22.645561071289258,Alt=4.900000095367432]_DATE_03_07_2019_14_40_29.png', 'ID_00109_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193244676881,Lon=22.645691290765114,Alt=5.0]_DATE_03_07_2019_14_40_31.png', 'ID_00110_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541930847402305,Lon=22.645747946119535,Alt=5.0]_DATE_03_07_2019_14_40_32.png', 'ID_00111_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193005334696,Lon=22.645817738398737,Alt=5.0]_DATE_03_07_2019_14_40_36.png', 'ID_00112_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193291242563,Lon=22.64588705755348,Alt=5.0]_DATE_03_07_2019_14_40_39.png', 'ID_00114_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541933951503175,Lon=22.646041640206185,Alt=5.0]_DATE_03_07_2019_14_40_45.png', 'ID_00115_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193493669876,Lon=22.64617081087172,Alt=4.900000095367432]_DATE_03_07_2019_14_40_48.png', 'ID_00116_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193509084076,Lon=22.64617422028293,Alt=4.900000095367432]_DATE_03_07_2019_14_40_50.png', 'ID_00118_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542022699877144,Lon=22.64618445100505,Alt=4.900000095367432]_DATE_03_07_2019_14_40_55.png', 'ID_00119_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542103453815685,Lon=22.64615423867319,Alt=4.900000095367432]_DATE_03_07_2019_14_40_57.png', 'ID_00120_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54210226914222,Lon=22.646142643191187,Alt=5.0]_DATE_03_07_2019_14_40_58.png', 'ID_00122_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54210052282493,Lon=22.645968990205468,Alt=4.900000095367432]_DATE_03_07_2019_14_40_59.png', 'ID_00123_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54210028092935,Lon=22.645903079750937,Alt=4.900000095367432]_DATE_03_07_2019_14_41_01.png', 'ID_00124_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54209917400431,Lon=22.6458356688693,Alt=4.900000095367432]_DATE_03_07_2019_14_41_04.png', 'ID_00126_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54210193198917,Lon=22.645691815525772,Alt=4.900000095367432]_DATE_03_07_2019_14_41_09.png', 'ID_00128_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54210217419742,Lon=22.645552923301274,Alt=5.0]_DATE_03_07_2019_14_41_12.png', 'ID_00129_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542102571277205,Lon=22.645483517538135,Alt=5.0]_DATE_03_07_2019_14_41_15.png', 'ID_00130_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54210323140932,Lon=22.645413601345382,Alt=5.0]_DATE_03_07_2019_14_41_17.png', 'ID_00131_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54210314230086,Lon=22.645346882175524,Alt=5.0]_DATE_03_07_2019_14_41_20.png', 'ID_00135_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.5421032925867,Lon=22.64506277085889,Alt=5.0]_DATE_03_07_2019_14_41_27.png', 'ID_00136_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54210393948282,Lon=22.644992056004764,Alt=5.0]_DATE_03_07_2019_14_41_27.png', 'ID_00137_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.5421067057011,Lon=22.644924984468943,Alt=5.0]_DATE_03_07_2019_14_41_29.png', 'ID_00138_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54210701481885,Lon=22.644849797228876,Alt=5.0]_DATE_03_07_2019_14_41_31.png', 'ID_00141_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54210710340621,Lon=22.644641749445736,Alt=5.0]_DATE_03_07_2019_14_41_41.png', 'ID_00142_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54210676625316,Lon=22.644570296231713,Alt=5.0]_DATE_03_07_2019_14_41_43.png', 'ID_00144_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542106241399146,Lon=22.644411160617047,Alt=4.900000095367432]_DATE_03_07_2019_14_41_49.png', 'ID_00145_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54218646912881,Lon=22.644424401747415,Alt=5.0]_DATE_03_07_2019_14_41_49.png', 'ID_00146_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542189351344405,Lon=22.64442459802719,Alt=5.099999904632568]_DATE_03_07_2019_14_41_51.png', 'ID_00147_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54226945067451,Lon=22.64442726480141,Alt=5.0]_DATE_03_07_2019_14_41_54.png', 'ID_00148_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54228269271211,Lon=22.644441385524676,Alt=5.0]_DATE_03_07_2019_14_41_57.png', 'ID_00150_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54227810300132,Lon=22.644643009866716,Alt=4.900000095367432]_DATE_03_07_2019_14_41_58.png', 'ID_00151_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542278121761,Lon=22.644646552367792,Alt=4.900000095367432]_DATE_03_07_2019_14_41_58.png', 'ID_00152_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54227882686422,Lon=22.64469144808864,Alt=4.900000095367432]_DATE_03_07_2019_14_41_59.png', 'ID_00153_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54227914239153,Lon=22.644760839809578,Alt=4.900000095367432]_DATE_03_07_2019_14_42_01.png', 'ID_00154_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54227850232185,Lon=22.6448305089751,Alt=4.900000095367432]_DATE_03_07_2019_14_42_05.png', 'ID_00156_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54227870268559,Lon=22.644969548798258,Alt=5.0]_DATE_03_07_2019_14_42_09.png', 'ID_00157_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54227988350291,Lon=22.645040147104332,Alt=5.0]_DATE_03_07_2019_14_42_11.png', 'ID_00159_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54228062602126,Lon=22.645181976164107,Alt=4.900000095367432]_DATE_03_07_2019_14_42_16.png', 'ID_00160_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54228158959111,Lon=22.645250989174674,Alt=4.900000095367432]_DATE_03_07_2019_14_42_19.png', 'ID_00162_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.5422813419113,Lon=22.645436838479792,Alt=5.0]_DATE_03_07_2019_14_42_23.png', 'ID_00163_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54227890013117,Lon=22.645515466526057,Alt=5.0]_DATE_03_07_2019_14_42_26.png', 'ID_00164_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542279083507,Lon=22.645575137487896,Alt=5.0]_DATE_03_07_2019_14_42_27.png', 'ID_00165_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54227935703348,Lon=22.645651256268124,Alt=5.0]_DATE_03_07_2019_14_42_28.png', 'ID_00166_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542280228420374,Lon=22.645707288255405,Alt=5.0]_DATE_03_07_2019_14_42_28.png', 'ID_00167_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542280769949656,Lon=22.645747994867307,Alt=5.0]_DATE_03_07_2019_14_42_30.png', 'ID_00168_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54230450578458,Lon=22.645749401931546,Alt=5.099999904632568]_DATE_03_07_2019_14_42_32.png', 'ID_00170_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54241457364314,Lon=22.645743751011544,Alt=5.0]_DATE_03_07_2019_14_42_37.png', 'ID_00173_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54244822829137,Lon=22.645611406186134,Alt=4.900000095367432]_DATE_03_07_2019_14_42_44.png', 'ID_00174_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54244811839094,Lon=22.64553941692437,Alt=4.900000095367432]_DATE_03_07_2019_14_42_46.png', 'ID_00175_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.5424479716486,Lon=22.64547362071826,Alt=4.900000095367432]_DATE_03_07_2019_14_42_48.png', 'ID_00176_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542448268989446,Lon=22.645401432777106,Alt=4.900000095367432]_DATE_03_07_2019_14_42_52.png', 'ID_00177_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54244840442387,Lon=22.645332618430654,Alt=4.900000095367432]_DATE_03_07_2019_14_42_54.png', 'ID_00178_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54244922411745,Lon=22.645222065848117,Alt=4.900000095367432]_DATE_03_07_2019_14_42_57.png', 'ID_00179_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54244953485062,Lon=22.64512810947972,Alt=4.900000095367432]_DATE_03_07_2019_14_42_58.png', 'ID_00180_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542450457670284,Lon=22.645034017294122,Alt=5.0]_DATE_03_07_2019_14_42_58.png', 'ID_00181_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54245048565347,Lon=22.645030463950338,Alt=5.0]_DATE_03_07_2019_14_42_59.png', 'ID_00182_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542450018746,Lon=22.644981928666137,Alt=4.900000095367432]_DATE_03_07_2019_14_43_00.png', 'ID_00183_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542451006911875,Lon=22.644911984033477,Alt=4.900000095367432]_DATE_03_07_2019_14_43_02.png', 'ID_00185_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54250017044385,Lon=22.644865573576695,Alt=5.0]_DATE_03_07_2019_14_43_08.png', 'ID_00186_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.5425572642636,Lon=22.644868443140762,Alt=5.0]_DATE_03_07_2019_14_43_11.png', 'ID_00187_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54261113579653,Lon=22.64486757250199,Alt=5.0]_DATE_03_07_2019_14_43_12.png', 'ID_00189_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542625897758604,Lon=22.64496170014026,Alt=4.900000095367432]_DATE_03_07_2019_14_43_19.png', 'ID_00190_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54262593006693,Lon=22.645067221015047,Alt=4.900000095367432]_DATE_03_07_2019_14_43_22.png', 'ID_00191_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54262753683309,Lon=22.64517786753953,Alt=4.900000095367432]_DATE_03_07_2019_14_43_23.png', 'ID_00192_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54262758240346,Lon=22.6451813086554,Alt=4.900000095367432]_DATE_03_07_2019_14_43_25.png', 'ID_00193_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54262905300564,Lon=22.645331020907935,Alt=4.900000095367432]_DATE_03_07_2019_14_43_27.png', 'ID_00194_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542629069628795,Lon=22.645334466268956,Alt=4.900000095367432]_DATE_03_07_2019_14_43_28.png', 'ID_00195_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54262912510011,Lon=22.645460848712993,Alt=5.0]_DATE_03_07_2019_14_43_29.png', 'ID_00196_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542629059623636,Lon=22.645464288074976,Alt=5.0]_DATE_03_07_2019_14_43_29.png', 'ID_00197_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.542628004860916,Lon=22.645521242026163,Alt=5.0]_DATE_03_07_2019_14_43_30.png', 'ID_00202_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54262757609813,Lon=22.645890716124914,Alt=4.900000095367432]_DATE_03_07_2019_14_43_43.png', 'ID_00205_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54254211045881,Lon=22.645969685649987,Alt=5.0]_DATE_03_07_2019_14_43_49.png', 'ID_00206_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54249635915536,Lon=22.645965651005273,Alt=5.0]_DATE_03_07_2019_14_43_52.png', 'ID_00210_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54227537513616,Lon=22.64599929514477,Alt=5.0]_DATE_03_07_2019_14_43_58.png', 'ID_00219_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54215672712343,Lon=22.64641393321042,Alt=5.0]_DATE_03_07_2019_14_44_20.png', 'ID_00223_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54193796888754,Lon=22.646416522930284,Alt=5.0]_DATE_03_07_2019_14_44_27.png', 'ID_00224_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54183592563622,Lon=22.646419560312,Alt=5.0]_DATE_03_07_2019_14_44_28.png', 'ID_00225_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54179345779697,Lon=22.646422431320282,Alt=5.0]_DATE_03_07_2019_14_44_29.png', 'ID_00226_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541749626650464,Lon=22.646418697960794,Alt=4.900000095367432]_DATE_03_07_2019_14_44_31.png', 'ID_00228_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54175574480575,Lon=22.646280737765263,Alt=4.900000095367432]_DATE_03_07_2019_14_44_37.png', 'ID_00229_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541755312082586,Lon=22.6462116238222,Alt=4.900000095367432]_DATE_03_07_2019_14_44_39.png', 'ID_00230_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54175433876812,Lon=22.646140932353227,Alt=4.900000095367432]_DATE_03_07_2019_14_44_41.png', 'ID_00231_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54175308937378,Lon=22.64606655089562,Alt=4.900000095367432]_DATE_03_07_2019_14_44_43.png', 'ID_00232_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541753271551066,Lon=22.645996861400004,Alt=4.900000095367432]_DATE_03_07_2019_14_44_45.png', 'ID_00233_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541743611152285,Lon=22.645966077070575,Alt=5.0]_DATE_03_07_2019_14_44_48.png', 'ID_00234_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54168750940668,Lon=22.645973817257005,Alt=5.0]_DATE_03_07_2019_14_44_50.png', 'ID_00235_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54161443494947,Lon=22.645974272117712,Alt=4.900000095367432]_DATE_03_07_2019_14_44_53.png', 'ID_00237_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54148944413435,Lon=22.64597508692096,Alt=5.0]_DATE_03_07_2019_14_44_57.png', 'ID_00238_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54142500569346,Lon=22.645975014576948,Alt=5.0]_DATE_03_07_2019_14_44_58.png', 'ID_00241_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541409415986784,Lon=22.645729935172934,Alt=4.900000095367432]_DATE_03_07_2019_14_45_07.png', 'ID_00254_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54106399836691,Lon=22.64531958914424,Alt=4.900000095367432]_DATE_03_07_2019_14_45_31.png', 'ID_00261_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541063660692764,Lon=22.64479158454532,Alt=4.900000095367432]_DATE_03_07_2019_14_45_58.png', 'ID_00262_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54088448828897,Lon=22.644641804370302,Alt=5.0]_DATE_03_07_2019_14_46_00.png', 'ID_00263_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54087900129252,Lon=22.644641774463963,Alt=4.900000095367432]_DATE_03_07_2019_14_46_05.png', 'ID_00264_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54087620922758,Lon=22.644641760821695,Alt=4.900000095367432]_DATE_03_07_2019_14_46_08.png', 'ID_00265_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54087340444775,Lon=22.644641739891703,Alt=4.900000095367432]_DATE_03_07_2019_14_46_10.png', 'ID_00266_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.540870610923726,Lon=22.644641727982496,Alt=4.900000095367432]_DATE_03_07_2019_14_46_15.png', 'ID_00267_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54086784512233,Lon=22.644641747446055,Alt=4.900000095367432]_DATE_03_07_2019_14_46_18.png', 'ID_00268_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.540718340102096,Lon=22.644235406189065,Alt=5.0]_DATE_03_07_2019_14_46_22.png', 'ID_00269_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.540718301957426,Lon=22.644228528353846,Alt=5.0]_DATE_03_07_2019_14_46_24.png', 'ID_00270_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.540718273817916,Lon=22.644225065617817,Alt=4.900000095367432]_DATE_03_07_2019_14_46_27.png', 'ID_00273_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54081008491725,Lon=22.643980389216125,Alt=5.0]_DATE_03_07_2019_14_46_29.png', 'ID_00274_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.540812635816145,Lon=22.643980494443767,Alt=5.0]_DATE_03_07_2019_14_46_29.png', 'ID_00275_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.540815211311056,Lon=22.643980613713612,Alt=5.0]_DATE_03_07_2019_14_46_30.png', 'ID_00276_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54081788248032,Lon=22.64398072773985,Alt=5.0]_DATE_03_07_2019_14_46_31.png', 'ID_00277_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54082057095016,Lon=22.64398085323093,Alt=5.0]_DATE_03_07_2019_14_46_31.png', 'ID_00280_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54088989003312,Lon=22.643983992107557,Alt=4.900000095367432]_DATE_03_07_2019_14_46_35.png', 'ID_00281_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.540885727469714,Lon=22.64404470125919,Alt=4.900000095367432]_DATE_03_07_2019_14_46_38.png', 'ID_00282_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54088680448349,Lon=22.644115068246638,Alt=4.900000095367432]_DATE_03_07_2019_14_46_40.png', 'ID_00285_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.540886848881385,Lon=22.644419760044062,Alt=4.900000095367432]_DATE_03_07_2019_14_46_50.png', 'ID_00286_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54088685972031,Lon=22.644421570777183,Alt=4.900000095367432]_DATE_03_07_2019_14_46_52.png', 'ID_00287_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.5410230443292,Lon=22.644415278892858,Alt=4.900000095367432]_DATE_03_07_2019_14_46_56.png', 'ID_00289_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54103113725293,Lon=22.644415390252853,Alt=4.900000095367432]_DATE_03_07_2019_14_46_58.png', 'ID_00290_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54106013345701,Lon=22.64423064099432,Alt=4.900000095367432]_DATE_03_07_2019_14_46_59.png', 'ID_00291_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54106004945535,Lon=22.644216494808454,Alt=4.900000095367432]_DATE_03_07_2019_14_46_59.png', 'ID_00293_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54105957295961,Lon=22.644147475872444,Alt=4.900000095367432]_DATE_03_07_2019_14_47_00.png', 'ID_00294_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541059901879244,Lon=22.644077924221488,Alt=4.900000095367432]_DATE_03_07_2019_14_47_03.png', 'ID_00296_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54106706390622,Lon=22.643969863518876,Alt=4.900000095367432]_DATE_03_07_2019_14_47_11.png', 'ID_00300_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54123656548919,Lon=22.64403500520726,Alt=4.900000095367432]_DATE_03_07_2019_14_47_18.png', 'ID_00303_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54123636434379,Lon=22.644265549465285,Alt=4.900000095367432]_DATE_03_07_2019_14_47_27.png', 'ID_00304_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541238256569656,Lon=22.644384945158155,Alt=4.900000095367432]_DATE_03_07_2019_14_47_28.png', 'ID_00305_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54123826636638,Lon=22.644388364523333,Alt=4.900000095367432]_DATE_03_07_2019_14_47_28.png', 'ID_00307_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54124004165694,Lon=22.644512413073326,Alt=4.900000095367432]_DATE_03_07_2019_14_47_29.png', 'ID_00311_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54123596559648,Lon=22.644795361675598,Alt=4.900000095367432]_DATE_03_07_2019_14_47_39.png', 'ID_00312_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541235265443724,Lon=22.644875775681168,Alt=4.900000095367432]_DATE_03_07_2019_14_47_41.png', 'ID_00313_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541238043543125,Lon=22.64494454825651,Alt=4.900000095367432]_DATE_03_07_2019_14_47_43.png', 'ID_00324_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541406496981374,Lon=22.645176476556752,Alt=4.900000095367432]_DATE_03_07_2019_14_48_06.png', 'ID_00325_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54140601444085,Lon=22.645104736125393,Alt=4.900000095367432]_DATE_03_07_2019_14_48_09.png', 'ID_00326_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54140551199423,Lon=22.645036216420788,Alt=4.900000095367432]_DATE_03_07_2019_14_48_12.png', 'ID_00330_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.5414068380948,Lon=22.64469183607114,Alt=5.0]_DATE_03_07_2019_14_48_20.png', 'ID_00331_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54140719921854,Lon=22.64463624321375,Alt=4.900000095367432]_DATE_03_07_2019_14_48_22.png', 'ID_00336_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54140952802373,Lon=22.644262318070098,Alt=5.0]_DATE_03_07_2019_14_48_30.png', 'ID_00337_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54140991405615,Lon=22.644197579961727,Alt=5.0]_DATE_03_07_2019_14_48_32.png', 'ID_00339_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.5414099372973,Lon=22.644060331385912,Alt=5.0]_DATE_03_07_2019_14_48_38.png', 'ID_00340_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.5414105595974,Lon=22.643988006222216,Alt=5.0]_DATE_03_07_2019_14_48_41.png', 'ID_00341_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541410933852916,Lon=22.64392007529028,Alt=5.0]_DATE_03_07_2019_14_48_44.png', 'ID_00342_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54141018065197,Lon=22.64383881128709,Alt=5.0]_DATE_03_07_2019_14_48_47.png', 'ID_00344_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.5414113820007,Lon=22.643652590263535,Alt=5.0]_DATE_03_07_2019_14_48_52.png', 'ID_00345_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541411356570926,Lon=22.64364584449612,Alt=5.0]_DATE_03_07_2019_14_48_54.png', 'ID_00346_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54142569042159,Lon=22.643528090674444,Alt=5.0]_DATE_03_07_2019_14_48_55.png', 'ID_00347_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541427973890904,Lon=22.64352864454157,Alt=5.0]_DATE_03_07_2019_14_48_57.png', 'ID_00348_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54150950708549,Lon=22.64353821581342,Alt=5.0]_DATE_03_07_2019_14_48_58.png', 'ID_00351_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54158451712426,Lon=22.643557174386498,Alt=5.0]_DATE_03_07_2019_14_49_00.png', 'ID_00353_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.5415832258333,Lon=22.64369504490746,Alt=5.0]_DATE_03_07_2019_14_49_06.png', 'ID_00354_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54158375172952,Lon=22.643766327393184,Alt=5.0]_DATE_03_07_2019_14_49_09.png', 'ID_00355_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54158417548973,Lon=22.64383407079951,Alt=5.0]_DATE_03_07_2019_14_49_10.png', 'ID_00358_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54158534067398,Lon=22.644032626298188,Alt=5.0]_DATE_03_07_2019_14_49_17.png', 'ID_00359_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54158546969885,Lon=22.644107871884493,Alt=5.0]_DATE_03_07_2019_14_49_19.png', 'ID_00362_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541586655935625,Lon=22.64432125586011,Alt=5.0]_DATE_03_07_2019_14_49_27.png', 'ID_00363_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541587078340974,Lon=22.64438596872807,Alt=5.0]_DATE_03_07_2019_14_49_28.png', 'ID_00365_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541587278027286,Lon=22.64451430752641,Alt=5.0]_DATE_03_07_2019_14_49_29.png', 'ID_00367_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54158793023865,Lon=22.64464565611089,Alt=5.0]_DATE_03_07_2019_14_49_34.png', 'ID_00369_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54158758005806,Lon=22.644775251864107,Alt=5.0]_DATE_03_07_2019_14_49_39.png', 'ID_00372_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54158466886918,Lon=22.644975072894063,Alt=5.0]_DATE_03_07_2019_14_49_47.png', 'ID_00378_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541587348897174,Lon=22.645423362698,Alt=4.900000095367432]_DATE_03_07_2019_14_49_58.png', 'ID_00379_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54158672378312,Lon=22.645486819477618,Alt=4.900000095367432]_DATE_03_07_2019_14_49_59.png', 'ID_00380_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54158659725953,Lon=22.64550956749012,Alt=4.900000095367432]_DATE_03_07_2019_14_49_59.png', 'ID_00385_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.54166286284165,Lon=22.645741743332096,Alt=5.0]_DATE_03_07_2019_14_50_16.png', 'ID_00404_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.5417569850287,Lon=22.644628217472913,Alt=5.0]_DATE_03_07_2019_14_50_51.png', 'ID_00405_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541757654227986,Lon=22.644558076982637,Alt=5.0]_DATE_03_07_2019_14_50_53.png', 'ID_00407_UAV_dji.phantom.4.pro.hawk.1_[Lat=39.541758292161155,Lon=22.644408826234198,Alt=5.0]_DATE_03_07_2019_14_50_58.png']\n",
            "Found 201 labeled images. Train: 160, Val: 41\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\preme\\AppData\\Local\\Temp\\ipykernel_24024\\1050422477.py:75: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp and torch.cuda.is_available())\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dynamic pos_weight = 18.02\n",
            "\n",
            "Epoch 1/60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 0/80 [00:00<?, ?it/s]C:\\Users\\preme\\AppData\\Local\\Temp\\ipykernel_24024\\3104898798.py:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
            "                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.9890 | Val loss: 0.8570 | Val mIoU: 0.4535\n",
            "Per-class IoU:\n",
            "  Class 0: IoU=0.7814  (support=10312372 px, 95.95% of GT)\n",
            "  Class 1: IoU=0.1256  (support=435532 px, 4.05% of GT)\n",
            "Saved best model (mIoU=0.4535) to output\\best_model.pth\n",
            "\n",
            "Epoch 2/60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.8088 | Val loss: 0.7645 | Val mIoU: 0.4482\n",
            "Per-class IoU:\n",
            "  Class 0: IoU=0.7607  (support=10312372 px, 95.95% of GT)\n",
            "  Class 1: IoU=0.1357  (support=435532 px, 4.05% of GT)\n",
            "\n",
            "Epoch 3/60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.7271 | Val loss: 0.7357 | Val mIoU: 0.5331\n",
            "Per-class IoU:\n",
            "  Class 0: IoU=0.8668  (support=10312372 px, 95.95% of GT)\n",
            "  Class 1: IoU=0.1995  (support=435532 px, 4.05% of GT)\n",
            "Saved best model (mIoU=0.5331) to output\\best_model.pth\n",
            "\n",
            "Epoch 4/60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.6774 | Val loss: 0.6982 | Val mIoU: 0.6134\n",
            "Per-class IoU:\n",
            "  Class 0: IoU=0.9298  (support=10312372 px, 95.95% of GT)\n",
            "  Class 1: IoU=0.2969  (support=435532 px, 4.05% of GT)\n",
            "Saved best model (mIoU=0.6134) to output\\best_model.pth\n",
            "\n",
            "Epoch 5/60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.6306 | Val loss: 0.7455 | Val mIoU: 0.6312\n",
            "Per-class IoU:\n",
            "  Class 0: IoU=0.9455  (support=10312372 px, 95.95% of GT)\n",
            "  Class 1: IoU=0.3170  (support=435532 px, 4.05% of GT)\n",
            "Saved best model (mIoU=0.6312) to output\\best_model.pth\n",
            "\n",
            "Epoch 6/60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.6217 | Val loss: 0.7233 | Val mIoU: 0.6449\n",
            "Per-class IoU:\n",
            "  Class 0: IoU=0.9490  (support=10312372 px, 95.95% of GT)\n",
            "  Class 1: IoU=0.3408  (support=435532 px, 4.05% of GT)\n",
            "Saved best model (mIoU=0.6449) to output\\best_model.pth\n",
            "\n",
            "Epoch 7/60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.6004 | Val loss: 0.6895 | Val mIoU: 0.5160\n",
            "Per-class IoU:\n",
            "  Class 0: IoU=0.8455  (support=10312372 px, 95.95% of GT)\n",
            "  Class 1: IoU=0.1866  (support=435532 px, 4.05% of GT)\n",
            "\n",
            "Epoch 8/60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.5965 | Val loss: 0.6235 | Val mIoU: 0.6068\n",
            "Per-class IoU:\n",
            "  Class 0: IoU=0.9211  (support=10312372 px, 95.95% of GT)\n",
            "  Class 1: IoU=0.2924  (support=435532 px, 4.05% of GT)\n",
            "\n",
            "Epoch 9/60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  74%|  | 59/80 [00:12<00:04,  4.82it/s]"
          ]
        }
      ],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
